{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Импортируем необходимые библиотеки","metadata":{}},{"cell_type":"code","source":"!pip install tmdbv3api","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom torch import nn\nfrom math import isnan, inf\nfrom copy import deepcopy\nfrom time import time_ns\nfrom torch.utils.data import Dataset\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import NearestNeighbors\n# from tmdbv3api import TMDb\n#from tmdbv3api import Movie\nfrom tqdm.notebook import tqdm\n\nimport re\nimport torch\nimport requests","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Первый этап: создание профилей фильмов\n- One-Hot Encoding для каждого жанра к которому принадлежит фильм, сумма таких векторов -- это закодированный жанр фильма\n- Дата выхода фильма на экране","metadata":{}},{"cell_type":"markdown","source":"## Загрузка необходимых таблиц","metadata":{}},{"cell_type":"code","source":"movies = pd.read_csv(\"/kaggle/input/movielensfull/ml-latest/movies.csv\")\nlinks = pd.read_csv(\"/kaggle/input/movielensfull/ml-latest/links.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Переводим жанры для фильма в формат One-Hot Encoding","metadata":{}},{"cell_type":"code","source":"genres = set()\n\nfor row in movies.itertuples():\n    genres.update(getattr(row, \"genres\").split(\"|\"))\n\ngenres = list(genres)\ngenres.remove('(no genres listed)')\n\ndef genresToVec(genre, text: str) -> np.array:\n    if genre in text:\n        return 1\n\n    return 0\n\nfor genre in genres:\n    movies[genre] = movies[\"genres\"].apply(lambda x: genresToVec(genre, x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Вытаскиваем год выхода из названия фильма","metadata":{}},{"cell_type":"code","source":"def extract_year(text: str) -> int:\n    search = re.search(\"\\(\\d\\d\\d\\d\\)\", text)\n    \n    if search is None:\n        return -1\n    else:\n        return search.group(0).replace(\"(\", \"\").replace(\")\", \"\")\n\nmovies[\"year\"] = movies[\"title\"].apply(extract_year)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Проблема: год есть в названии не всех фильмов\n\n- IMDB api воспользоваться не получится, так как аккаунт в AWS из России не завести\n- TMDB api было бы хорошим вариантом, но в табличке не для всех фильмов есть tmdbId, а те которые есть не все верные\n- __в качестве решния этой проблемы воспользуемся комбинированным подходом: используем поиск по id где это возможно, а иначе воспользуемся поиском по названию с помощью пакета tmdbv3api и, наконец, остатки разметим вручную__","metadata":{}},{"cell_type":"code","source":"tmdb = TMDb()\ntmdb.api_key = '2fb17a68b167a63f1ce5f42308454db6'\nmovie = Movie()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Заполняем пропуски по id","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:32:06.419292Z","iopub.execute_input":"2023-05-08T19:32:06.419767Z","iopub.status.idle":"2023-05-08T19:32:06.424885Z","shell.execute_reply.started":"2023-05-08T19:32:06.419729Z","shell.execute_reply":"2023-05-08T19:32:06.423711Z"}}},{"cell_type":"code","source":"tmdb = TMDb()\ntmdb.api_key = '2fb17a68b167a63f1ce5f42308454db6'\nmovie = Movie()\n\n\ndef get_year_by_id(tmdbId) -> str:\n    \n    if isnan(tmdbId):\n        return -1\n    try:\n        res = movie.details(int(tmdbId))[\"release_date\"][:4]\n        if len(res) < 4:\n            return -1\n        else:\n            return res\n    except Exception as e:\n        return -1    \n\n\nmoviesWL = pd.merge(movies, links, on=\"movieId\", how=\"left\")\nmovies[\"year\"][movies[\"year\"] == -1] = moviesWL[moviesWL[\"year\"] == -1][\"tmdbId\"].apply(get_year_by_id)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Заполняем пропуски по названию","metadata":{}},{"cell_type":"code","source":"def get_year_by_title(title: str) -> str:\n    try:\n        search = movie.search(title)[0][\"release_date\"][:4]\n        \n        if len(search) < 4:\n            return -1\n        else:\n            return search\n    except Exception as e:\n        return -1\n\nmovies[\"year\"][movies[\"year\"] == -1] = movies[movies[\"year\"] == -1][\"title\"].apply(get_year_by_title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Заполняем остатки пропусков вручную","metadata":{}},{"cell_type":"code","source":"for row in movies[movies[\"year\"] == -1].itertuples():\n    print(getattr(row, \"title\"))\n    movies.loc[getattr(row, \"Index\"), \"year\"] = input()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Проверяем датасет на отсутствие ошибок","metadata":{"execution":{"iopub.status.busy":"2023-05-09T07:08:12.250644Z","iopub.execute_input":"2023-05-09T07:08:12.251155Z","iopub.status.idle":"2023-05-09T07:08:12.257227Z","shell.execute_reply.started":"2023-05-09T07:08:12.251114Z","shell.execute_reply":"2023-05-09T07:08:12.255857Z"}}},{"cell_type":"code","source":"indexes = []\n\nfor row in movies.itertuples():\n    if len(str(getattr(row, \"year\"))) < 4:\n        indexes.append(getattr(row, \"Index\"))\n\nassert len(movies.iloc[indexes]) == 0, \"Что-то не так, перепроверить данные\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Сохраняем датасет в удобном для дальнейшего использования формате","metadata":{"execution":{"iopub.status.busy":"2023-05-09T07:09:01.925919Z","iopub.execute_input":"2023-05-09T07:09:01.927337Z","iopub.status.idle":"2023-05-09T07:09:01.933101Z","shell.execute_reply.started":"2023-05-09T07:09:01.927278Z","shell.execute_reply":"2023-05-09T07:09:01.931665Z"}}},{"cell_type":"code","source":"movies[\"year\"] = movies[\"year\"].apply(int)\nmovies.to_csv(\"movie_profiles.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Сохраняем файл для дальнейшего использования","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:33:21.149535Z","iopub.execute_input":"2023-05-08T19:33:21.149991Z","iopub.status.idle":"2023-05-08T19:33:21.154657Z","shell.execute_reply.started":"2023-05-08T19:33:21.149958Z","shell.execute_reply":"2023-05-08T19:33:21.153584Z"}}},{"cell_type":"code","source":"movies.to_csv(\"movie_profiles.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Второй этап: составляем профили пользователей\n\n- 19-ти мерный вектор средних оценок по жанрам\n- \"любимый год\": год с самой выской средней оценкой","metadata":{}},{"cell_type":"markdown","source":"## Загружаем необходимые датасеты","metadata":{}},{"cell_type":"code","source":"movies = pd.read_csv(\"/kaggle/input/movie-profiles-final/movie_profiles.csv\")\nratings = pd.read_csv(\"/kaggle/input/movielensfull/ml-latest/ratings.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ассоциируем отзыв с жанрами фильма на который он оставлен","metadata":{}},{"cell_type":"code","source":"reviews_with_genres = pd.merge(ratings.drop(columns=[\"timestamp\"]), movies.drop(columns=[\"title\", \"genres\"]), on=\"movieId\", how=\"left\")\n\nfor genre in genres:\n    reviews_with_genres[genre] = reviews_with_genres[genre] * reviews_with_genres[\"rating\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Создаём \"профиль\" юзера: вектор средних по жанрам","metadata":{}},{"cell_type":"code","source":"def create_user_profile(user):\n    \n    if user.iloc[0][\"userId\"] % 1000 == 0.0:\n        print(user.iloc[0][\"userId\"], end=\"\\r\")\n        \n    d = {}\n    \n    for genre in genres:\n        zeros = np.count_nonzero(user[genre] == 0)\n        \n        if zeros == user[genre].shape[0]:\n            d[genre] = 0\n        else:\n            d[genre] = np.sum(user[genre]) / (user[genre].shape[0] - zeros)\n    \n    return pd.Series(d, index=genres)\n        \n\nuser_profiles = reviews_with_genres.groupby(\"userId\").apply(create_user_profile)\nuser_profiles.reset_index(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Выявляем любимый год юзера: год с самой высокой средней оценкой","metadata":{}},{"cell_type":"code","source":"res = reviews_with_genres.groupby([\"userId\", \"year\"], as_index=False).agg({\"rating\": \"mean\"})\nuser_fav_years = res.iloc[res.groupby(\"userId\").agg({\"rating\": \"idxmax\"})[\"rating\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Добавляем любимый год в профиль и сохраняем датасет","metadata":{}},{"cell_type":"code","source":"user_profiles = pd.merge(user_profiles, user_fav_years[[\"userId\", \"year\"]], on=\"userId\", how=\"left\")\nuser_profiles.to_csv(\"user_profiles.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Третий этап: архитектура и обучение нейросети\n\nАрхитектура сети представлена в ячейке ниже","metadata":{}},{"cell_type":"markdown","source":"## EmbeddingNet","metadata":{}},{"cell_type":"code","source":"class EmbeddingNet(nn.Module):\n    def __init__(self, user_length=20, movie_length=20, output_length=50):\n        super().__init__()\n        \n        self.user_encoder = nn.Sequential(\n            nn.Linear(user_length, 128),\n            nn.Tanh(),\n            nn.Linear(128, 128),\n            nn.Tanh(),\n            nn.Linear(128, 128),\n            nn.Tanh(),\n            nn.Linear(128, output_length)\n        )\n        \n        self.movie_encoder = nn.Sequential(\n            nn.Linear(movie_length, 128),\n            nn.LeakyReLU(),\n            nn.Linear(128, 128),\n            nn.LeakyReLU(),\n            nn.Linear(128, 128),\n            nn.LeakyReLU(),\n            nn.Linear(128, output_length)\n        )\n        \n        self.cosine = nn.CosineSimilarity(dim=2)\n    \n    def forward(self, user, movie):\n        \n        user_embedding = self.user_encoder(user)\n        movie_embedding = self.movie_encoder(movie)\n\n        similarity = self.cosine(user_embedding, movie_embedding)\n        return (similarity + 1) * 2.5\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Создаём pytorch Dataset","metadata":{}},{"cell_type":"code","source":"class RatingsDataset(Dataset):\n    \n    def __init__(self, ratings, user_profiles, movie_profiles):\n        self.ratings = ratings\n        self.user_profiles = user_profiles\n        self.movie_profiles = movie_profiles\n        self.columns = ['Action', 'Mystery', 'Documentary', 'War', 'Comedy',\n       'Musical', 'Film-Noir', 'Adventure', 'Drama', 'Fantasy', 'Romance',\n       'Animation', 'Crime', 'Children', 'Thriller', 'IMAX', 'Sci-Fi',\n       'Western', 'Horror', 'year']\n    \n    def __len__(self):\n        return len(self.ratings)\n    \n    def __getitem__(self, idx):\n        review = self.ratings.iloc[idx]\n        user = torch.tensor(\n            self.user_profiles.loc[self.user_profiles[\"userId\"] == review[\"userId\"], self.columns].to_numpy(),\n            dtype=torch.float32\n        )\n        movie = torch.tensor(\n            self.movie_profiles.loc[self.movie_profiles[\"movieId\"] == review[\"movieId\"], self.columns].to_numpy(),\n            dtype=torch.float32\n        )\n        return user, movie, torch.tensor(review[\"rating\"], dtype=torch.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Загружаем необходимые датасеты","metadata":{}},{"cell_type":"code","source":"ratings = pd.read_csv(\"/kaggle/input/movielensfull/ml-latest/ratings.csv\")\nratings = ratings.groupby(\"rating\", group_keys=False).apply(lambda x: x.sample(frac=0.0075, random_state=42))\nuser_profiles = pd.read_csv(\"/kaggle/input/user-profiles-final/user_profiles.csv\")\nmovie_profiles = pd.read_csv(\"/kaggle/input/movie-profiles-final/movie_profiles.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Проводим train/val/test split и скалируем данные","metadata":{}},{"cell_type":"code","source":"ratings_train, ratings_val = train_test_split(ratings, test_size=0.4, random_state=42, stratify=ratings[\"rating\"])\nratings_val, ratings_test = train_test_split(ratings_val, test_size=0.5, random_state=42, stratify=ratings_val[\"rating\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"genres = ['Action', 'Mystery', 'Documentary', 'War', 'Comedy',\n       'Musical', 'Film-Noir', 'Adventure', 'Drama', 'Fantasy', 'Romance',\n       'Animation', 'Crime', 'Children', 'Thriller', 'IMAX', 'Sci-Fi',\n       'Western', 'Horror']\n\nfor genre in genres:\n    scaler = MinMaxScaler()\n    user_profiles[[genre]] = scaler.fit_transform(user_profiles[[genre]])\n    \nuser_scaler = StandardScaler()\nuser_profiles[[\"year\"]] = user_scaler.fit_transform(user_profiles[[\"year\"]])\n\nmovie_scaler = StandardScaler()\nmovie_profiles[[\"year\"]] = movie_scaler.fit_transform(movie_profiles[[\"year\"]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Подготавливаем pytorch даталоадеры","metadata":{}},{"cell_type":"code","source":"train_ds = RatingsDataset(ratings_train, user_profiles, movie_profiles)\nval_ds = RatingsDataset(ratings_val, user_profiles, movie_profiles)\ntest_ds = RatingsDataset(ratings_test, user_profiles, movie_profiles)\n\ntrain_dl = torch.utils.data.DataLoader(train_ds, batch_size=2028, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = torch.utils.data.DataLoader(val_ds, batch_size=2048, shuffle=True, num_workers=4, pin_memory=True)\ntest_dl = torch.utils.data.DataLoader(test_ds, batch_size=2048, shuffle=True, num_workers=4, pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Подготавливаем модель к обучению","metadata":{}},{"cell_type":"markdown","source":"### По возможности будем обучать на GPU","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Инициализируем модель, оптимизатор. В качестве loss-функции была выбрана MSE, она же выступает в качестве метрики качества","metadata":{}},{"cell_type":"code","source":"model = EmbeddingNet().to(device)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaders = { \"train\": train_dl, \"val\": val_dl }\nhistory = { \"train\": [], \"val\": [] }\n\nbest_model = deepcopy(model.state_dict())\nbest_loss = inf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_epochs = 20\n\nfor epoch in tqdm(range(max_epochs)):\n    \n    start = time_ns() * 1e-9\n    \n    train_losses = []\n    validation_losses = []\n    \n    if epoch == 10:\n        optimizer.param_groups[0][\"lr\"] = 0.0001\n        \n    if epoch == 15:\n        optimizer.param_groups[0][\"lr\"] = 0.00001\n    \n    for k, dataloader in loaders.items():\n\n        for user, movie, rating in tqdm(dataloader, total=len(dataloader)):\n            \n            user = user.to(device)\n            movie = movie.to(device)\n            rating = rating.to(device)\n            \n            optimizer.zero_grad()\n            \n            if k == \"train\":\n                model.train()\n                output = model(user, movie)\n            else:\n                model.eval()\n                with torch.no_grad():\n                    output = model(user, movie)\n            \n            if k == \"train\":\n                loss = criterion(torch.flatten(output), rating)\n                loss.backward()\n                optimizer.step()\n                train_losses.append(loss.detach().to(\"cpu\").item())\n            else:\n                with torch.no_grad():\n                    loss = criterion(torch.flatten(output), rating)\n                    validation_losses.append(loss.detach().to(\"cpu\").item())\n        \n    train_avg_loss = sum(train_losses) / len(train_losses)\n    history[\"train\"].append(train_avg_loss)\n    \n    val_avg_loss = sum(validation_losses) / len(validation_losses)\n    history[\"val\"].append(val_avg_loss)\n    \n    if val_avg_loss < best_loss:\n        best_loss = val_avg_loss\n        best_model = deepcopy(model.state_dict())\n    \n    end = time_ns() * 1e-9    \n    print(f\"Iteration №{epoch + 14}. Train MSE: {train_avg_loss}. Val MSE: {val_avg_loss}. Time used: {end - start}.\")\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = [i for i in range(1, len(history[\"train\"]) + 1)]\n\nplt.plot(X, history[\"train\"])\nplt.plot(X, history[\"val\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(best_model, \"model_val_200k_strata.pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(best_model)\nmodel.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score(model, dataloader, device, criterion):\n    \n    model.to(device)\n    model.eval()\n    \n    losses = []\n    \n    for user, movie, rating in tqdm(dataloader, total=len(dataloader)):\n            \n        user = user.to(device)\n        movie = movie.to(device)\n        rating = rating.to(device)\n            \n                \n        with torch.no_grad():\n            output = model(user, movie)\n            loss = criterion(torch.flatten(output), rating)\n            losses.append(loss.detach().to(\"cpu\").item())\n    \n    return sum(losses) / len(losses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score(model, test_dl, device, criterion)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"На тестовых данных модель получила score: 0.7643040248325893","metadata":{}},{"cell_type":"markdown","source":"# Четвёртый этап: получения эмбеддингов","metadata":{}},{"cell_type":"markdown","source":"## Создаём и сохраняем эмбеддинги","metadata":{"execution":{"iopub.status.busy":"2023-05-10T19:34:00.353782Z","iopub.status.idle":"2023-05-10T19:34:00.354625Z","shell.execute_reply.started":"2023-05-10T19:34:00.354345Z","shell.execute_reply":"2023-05-10T19:34:00.354373Z"}}},{"cell_type":"code","source":"embeddings = model.movie_encoder(torch.tensor(movie_profiles[genres + [\"year\"]].to_numpy(), dtype=torch.float32).to(device)).detach().to(\"cpu\").numpy()\nnp.save(\"embeddings.npy\", embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучаем объект NearestNeighbours на полученных эмбеддингах","metadata":{}},{"cell_type":"code","source":"knn = NearestNeighbors(n_neighbors=10, metric=\"cosine\").fit(embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Пример использования\n\n- создаём с помощью user_encoder-а из модели эмбеддинг юзера\n- с помощью метода NearestNeighbor kneighbors получаем индексы N ближайших фильмов\n- по этим индексам получаем фильмы с помощью таблицы movies","metadata":{}},{"cell_type":"code","source":"user_embedding = model.user_encoder(torch.tensor(user_profiles.iloc[0][genres + [\"year\"]].to_numpy(), dtype=torch.float32).to(device)).detach().to(\"cpu\").numpy()\n_, indices = knn.kneighbors([user_embedding])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies = pd.read_csv(\"/kaggle/input/movielensfull/ml-latest/movies.csv\")\nmovies.iloc[indices[0]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Пятый этап: пути дальнейшего развития","metadata":{}},{"cell_type":"markdown","source":"- Во-первых, на мой взгляд, у нас мало данных для обучения. К сожалению, у меня нет доступа к IMDB API, а TMDB API имеет лимит запросов кратно меньший количества фильмов в датасете, но \"given enough time\" можно было бы достать следующие данные: \n\n    1. Популярность фильма (по сути, рейтинг на сайте, т.е. число) \n\n    2. Страна выпуска/язык оригинала (можно представить в виде вектора таким образом, чтобы языки схожих культур находились бы ближе друг к другу) \n\n    3. Бюджет (число) \n\n    4. Длина фильма (число) \n\n    5. Выручка фильма (число) \n\n    6. Список актёров, режиссёр и сценарист (можно представить в виде векторов по аналогии с word2vec исходя из того, как часто они встречаются вместе/в фильмах одного жанра etc. \n  \n\n- Во-вторых, мои эксперименты показали, что обучение большей модели на большей выборке данных (с сохранением распределения классов) даёт лучшие результаты. В идеале можно было бы обучить модель на большей выборке, в том числе и на всём датасете, если бы на это было время и/или мощности. \n\n- В-третьих, можно было бы поэкспериментировать с различными функциями активации.\n\n- В четвёртых, можно было бы дообучать модель на нескольких выборках, ещё уменьшить learning rate","metadata":{}}]}